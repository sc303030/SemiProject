{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_recommendations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrNyHsg7_O1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive  # 구글 코랩에서 drive(내 구글 드라이브)를 사용하기 위한 함수\n",
        "import io\n",
        "drive.mount('/content/drive')  # 이렇게 하면 내 drive가 설정? 잡힌다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzg3OpS6_SIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install surprise\n",
        "!pip install tmdbv3api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A-sibiM_SmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # pandas 불러오기\n",
        "import numpy as np # numpy 불러오기\n",
        "import math # 불러오기 수학과 관련된 함수들\n",
        "import re #정규표현식 함수 .맞는지 틀린지\n",
        "from scipy.sparse import csr_matrix   # 매트릭스 해주는거.\n",
        "import matplotlib.pyplot as plt # 시각화 함수\n",
        "import seaborn as sns # 시각화 함수\n",
        "from surprise import Reader, Dataset, SVD, NormalPredictor, KNNBasic\n",
        "from surprise import KNNWithMeans, KNNWithZScore, KNNBaseline\n",
        "from surprise import BaselineOnly, SVDpp,NMF, SlopeOne, CoClustering #분석툴\n",
        "from surprise.accuracy import rmse\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate, KFold, train_test_split\n",
        "import json\n",
        "import mpmath\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNYgu6ljbhGY",
        "colab_type": "text"
      },
      "source": [
        "# 전처리 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w70BwxPf_V2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/ratings_small.csv',low_memory=False)\n",
        "ratings = ratings[['userId', 'movieId', 'rating']]\n",
        "ratings.head()\n",
        "ratings.movieId = pd.to_numeric(ratings.movieId, errors='coerce')\n",
        "ratings.userId = pd.to_numeric(ratings.userId, errors='coerce')\n",
        "ratings.rating = pd.to_numeric(ratings.rating, errors='coerce')\n",
        "len(ratings)\n",
        "df = ratings\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x3ThpwC_X6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = df.groupby('rating')['rating'].agg(['count'])\n",
        "movie_count = df['movieId'].nunique()\n",
        "cust_count = df['userId'].nunique()\n",
        "rating_count = df['userId'].count()\n",
        "df = df[pd.notnull(df['rating'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8FjpXux_Zmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7cb99936-3a63-48d9-8f50-4ac06e314368"
      },
      "source": [
        "f = ['count','mean']\n",
        "df_movie_summary = df.groupby('movieId')['rating'].agg(f)\n",
        "df_movie_summary.index = df_movie_summary.index.map(int) # map 함수 쓰면 한번에 형변환 처리 가능 , 스트나 튜플을 지정함수로 처리해주는 역할\n",
        "movie_benchmark = round(df_movie_summary['count'].quantile(0.7),0)  #quantile 사분위수\n",
        "drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n",
        "print('Movie minimum times of review: {}'.format(movie_benchmark))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie minimum times of review: 7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE9vJi5p_bxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d289d34c-0f14-4905-cbc3-bbad17ff0091"
      },
      "source": [
        "df_cust_summary = df.groupby('userId')['rating'].agg(f)\n",
        "df_cust_summary.index = df_cust_summary.index.map(int)\n",
        "cust_benchmark = round(df_cust_summary['count'].quantile(0.7),0)\n",
        "drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n",
        "print('Customer minimum times of review: {}'.format(cust_benchmark))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Customer minimum times of review: 138.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOHKFLDj_dG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print('Original Shape: {}'.format(df.shape))\n",
        "df = df[~df['movieId'].isin(drop_movie_list)] # df의 'Movie_Id'에서 drop_movie_list의 값이 있으면 True\n",
        "# print('df not isin dropmovie', df)\n",
        "df = df[~df['userId'].isin(drop_cust_list)]\n",
        "# print('df not isin dropcust', df)\n",
        "# print('After Trim Shape: {}'.format(df.shape))\n",
        "# print('-Data Examples-')\n",
        "# print(df.iloc[::5000000, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KcDNZdg_fLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_p = pd.pivot_table(df,values='rating',index='userId',columns='movieId')\n",
        "# print(df_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DGcI1HQ_hB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/movies_metadata.csv',low_memory=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuwVGVq87B63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta = meta[['id', 'original_title', 'genres','release_date','popularity','original_language']]\n",
        "meta = meta.rename(columns={'id':'movieId'})\n",
        "meta.movieId = pd.to_numeric(meta.movieId, errors='coerce')\n",
        "meta.popularity = pd.to_numeric(meta.popularity, errors='coerce')   # popularity를 문자열에서 숫자형으로 변환!\n",
        "\n",
        "# meta.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr_tyZbbrmDI",
        "colab_type": "text"
      },
      "source": [
        "# 필요한 함수와 알고리즘 구현부"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIVC-Vm4Fhcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user_release_ratio(df, usernumber):\n",
        "    user_df =df[df['userId'] == usernumber]\n",
        "    meta2 = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/movies_metadata.csv',low_memory=False)\n",
        "    value_meta = meta2[['id','original_title','release_date', 'genres']]\n",
        "\n",
        "    value_meta = value_meta.rename(columns={'id':'movieId'})\n",
        "    value_meta.movieId = pd.to_numeric(value_meta.movieId, errors='coerce')\n",
        "    value_meta = value_meta.dropna(axis=0)\n",
        "    value_meta = value_meta.reset_index()\n",
        "    merge_data = pd.merge(user_df, value_meta, on='movieId', how='left')\n",
        "    merge_data = merge_data.dropna(axis=0)\n",
        "    merge_data = merge_data.reset_index()\n",
        "\n",
        "    release_date_list = {'1900':0,'1950':0,'1960':0,'1970':0,'1980':0,'1990':0,'2000':0,'2010':0,'2020':0}\n",
        "    for i in range(0,len(merge_data)):\n",
        "        if int(merge_data['release_date'].loc[i][0:4]) <= 1900:\n",
        "            release_date_list[\"1900\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 1950:\n",
        "            release_date_list[\"1950\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 1960:\n",
        "            release_date_list[\"1960\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 1970:\n",
        "            release_date_list[\"1970\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 1980:\n",
        "            release_date_list[\"1980\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 1990:\n",
        "            release_date_list[\"1990\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 2000:\n",
        "            release_date_list[\"2000\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 2010:\n",
        "            release_date_list[\"2010\"] += 1\n",
        "        elif int(merge_data['release_date'].loc[i][0:4]) <= 2020:\n",
        "            release_date_list[\"2020\"] += 1\n",
        "    release_date_list\n",
        "\n",
        "    sum = 0\n",
        "    for i in release_date_list:\n",
        "\n",
        "        sum += release_date_list[i]\n",
        "\n",
        "    release_date_rate = []\n",
        "    for i in release_date_list:\n",
        "        if release_date_list[i] ==0:\n",
        "            continue\n",
        "        release_date_list[i] = round((release_date_list[i]/sum),3)\n",
        "    return release_date_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3cqMoQDRGqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Estimate_Score_sum1(user_df, user_release_ratio_list):\n",
        "    user_df = user_df.dropna(axis=0)\n",
        "    for i in range(0,len(user_df)):\n",
        "        if int(user_df.iloc[i]['release_date'][0:4]) <= 1900:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['1900']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4]) <= 1950:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]]= user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['1950']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4]) <= 1960:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['1960']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4]) <= 1970:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['1970']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4]) <= 1980:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['1980']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4]) <= 1990:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['1990']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4])  <= 2000:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['2000']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4])  <= 2010:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['2010']\n",
        "        elif int(user_df.iloc[i]['release_date'][0:4])  <= 2020:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_release_ratio_list['2020']\n",
        "    return user_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yebMQkK34Oi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user_pop_ratio(df, usernumber):\n",
        "    user_df =df[df['userId'] == usernumber]\n",
        "    meta2 = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/movies_metadata.csv',low_memory=False)\n",
        "    value_meta = meta2[['id','original_title', 'popularity','genres']]\n",
        "\n",
        "    value_meta = value_meta.rename(columns={'id':'movieId'})\n",
        "    value_meta.movieId = pd.to_numeric(value_meta.movieId, errors='coerce')\n",
        "    value_meta.popularity = pd.to_numeric(value_meta.popularity, errors='coerce') \n",
        "    value_meta = value_meta.dropna(axis=0)\n",
        "    value_meta = value_meta.reset_index()\n",
        "    merge_data = pd.merge(user_df, value_meta, on='movieId', how='left')\n",
        "    merge_data = merge_data.dropna(axis=0)\n",
        "    merge_data = merge_data.reset_index()\n",
        "\n",
        "    popularity_list = {'2':0,'6':0,'9':0,'13':0,'18':0,'31':0,'64':0,'185':0,'288':0, '547':0}\n",
        "    for i in range(0,len(merge_data)):\n",
        "        if int(merge_data['popularity'].loc[i]) <= 2:\n",
        "            popularity_list[\"2\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 6:\n",
        "            popularity_list[\"6\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 9:\n",
        "            popularity_list[\"9\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 13:\n",
        "            popularity_list[\"13\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 18:\n",
        "            popularity_list[\"18\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 31:\n",
        "            popularity_list[\"31\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 64:\n",
        "            popularity_list[\"64\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 185:\n",
        "            popularity_list[\"185\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 288:\n",
        "            popularity_list[\"288\"] += 1\n",
        "        elif int(merge_data['popularity'].loc[i]) <= 547:\n",
        "            popularity_list[\"547\"] += 1\n",
        "    # popularity_list\n",
        "\n",
        "    sum = 0\n",
        "    for i in popularity_list:\n",
        "\n",
        "        sum += popularity_list[i]\n",
        "\n",
        "    #popularity_list = []\n",
        "    for i in popularity_list:\n",
        "        if popularity_list[i] ==0:\n",
        "            continue\n",
        "        popularity_list[i] = round((popularity_list[i]/sum),3)\n",
        "    return popularity_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4OAhV89R35v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Estimate_Score_sum2(user_df, user_pop_ratio_list):\n",
        "    user_df = user_df.dropna(axis=0)\n",
        "    for i in range(0,len(user_df)):\n",
        "        if int(user_df.iloc[i]['popularity']) <= 2:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['2']\n",
        "        elif int(user_df.iloc[i]['popularity']) <= 6:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['6']\n",
        "        elif int(user_df.iloc[i]['popularity']) <= 9:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['9']\n",
        "        elif int(user_df.iloc[i]['popularity']) <= 13:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['13']\n",
        "        elif int(user_df.iloc[i]['popularity']) <= 18:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['18']\n",
        "        elif int(user_df.iloc[i]['popularity']) <= 31:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['31']\n",
        "        elif int(user_df.iloc[i]['popularity'])  <= 64:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['64']\n",
        "        elif int(user_df.iloc[i]['popularity'])  <= 185:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['185']\n",
        "        elif int(user_df.iloc[i]['popularity'])  <= 288:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['288']\n",
        "        elif int(user_df.iloc[i]['popularity'])  <= 547:\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_pop_ratio_list['547']\n",
        "    return user_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sFz8wCnR47t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user_language_ratio(df, usernumber):\n",
        "    user_df =df[df['userId'] == usernumber]\n",
        "    meta2 = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/movies_metadata.csv',low_memory=False)\n",
        "    value_meta = meta2[['id','original_title', 'original_language','genres']]\n",
        "\n",
        "    value_meta = value_meta.rename(columns={'id':'movieId'})\n",
        "    value_meta.movieId = pd.to_numeric(value_meta.movieId, errors='coerce')\n",
        "    # value_meta.popularity = pd.to_numeric(value_meta.popularity, errors='coerce') \n",
        "    value_meta = value_meta.dropna(axis=0)\n",
        "    value_meta = value_meta.reset_index()\n",
        "    merge_data = pd.merge(user_df, value_meta, on='movieId', how='left')\n",
        "    merge_data = merge_data.dropna(axis=0)\n",
        "    merge_data = merge_data.reset_index()\n",
        "\n",
        "    original_language_list = {'en':0,'fr':0,'it':0,'ja':0,'de':0}\n",
        "    for i in range(0,len(merge_data)):\n",
        "        if merge_data['original_language'].loc[i] == 'en':\n",
        "            original_language_list[\"en\"] += 1\n",
        "        elif merge_data['original_language'].loc[i] == 'fr':\n",
        "            original_language_list[\"fr\"] += 1\n",
        "        elif merge_data['original_language'].loc[i] == 'it':\n",
        "            original_language_list[\"it\"] += 1\n",
        "        elif merge_data['original_language'].loc[i] == 'ja':\n",
        "            original_language_list[\"ja\"] += 1\n",
        "        elif merge_data['original_language'].loc[i] == 'de':\n",
        "            original_language_list[\"de\"] += 1\n",
        "       \n",
        "    # original_language_list\n",
        "\n",
        "    sum = 0\n",
        "    for i in original_language_list:\n",
        "\n",
        "        sum += original_language_list[i]\n",
        "\n",
        "    # popularity_list = []\n",
        "    for i in original_language_list:\n",
        "        if original_language_list[i] ==0:\n",
        "            continue\n",
        "        original_language_list[i] = round((original_language_list[i]/sum),3)\n",
        "\n",
        "    return original_language_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7hY1_LxSSDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Estimate_Score_sum3(user_df, user_language_ratio_list):\n",
        "    user_df = user_df.dropna(axis=0)\n",
        "    for i in range(0,len(user_df)):\n",
        "        if user_df.iloc[i]['original_language'] == 'en':\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_language_ratio_list['en']\n",
        "        elif user_df.iloc[i]['original_language'] == 'fr':\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_language_ratio_list['fr']\n",
        "        elif user_df.iloc[i]['original_language'] == 'it':\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_language_ratio_list['it']\n",
        "        elif user_df.iloc[i]['original_language'] == 'ja':\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_language_ratio_list['ja']\n",
        "        elif user_df.iloc[i]['original_language'] == 'de':\n",
        "            user_df['Estimate_Score'].loc[user_df.index[i]] = user_df.iloc[i]['Estimate_Score'] + user_language_ratio_list['de']\n",
        "       \n",
        "    return user_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENqU4GvaoQ16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#우선 사용할 것들을 다시 불러오는 부분\n",
        "def user_vote_ratio():\n",
        "  meta = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/movies_metadata.csv',low_memory=False)\n",
        "  meta = meta[['id', 'original_title', 'genres','poster_path','vote_average','vote_count']]\n",
        "  meta = meta.rename(columns={'id':'movieId'})\n",
        "  meta.movieId = pd.to_numeric(meta.movieId, errors='coerce')\n",
        "  meta.head()\n",
        "  meta.vote_average =  pd.to_numeric(meta.vote_average, errors='coerce') #데이터프레임의 숫자들이 문자여서 숫자로 바꿨습니다.\n",
        "  meta.vote_count =  pd.to_numeric(meta.vote_count, errors='coerce')\n",
        "  meta = meta[['movieId','original_title','poster_path','vote_average','vote_count','genres']].dropna() #결측값 제거\n",
        "  mata = meta.reset_index(inplace=True,drop=True)\n",
        "  meta.index = meta.index.map(int)\n",
        "  \n",
        "  meta['vote_round'] = ''  # 예를들어 구간을 6.0 6.5 7.0 이런식으로 나눌 예정이므로 추가\n",
        "  meta['Adj'] = '' #예측치에 가중치를 더하기 위해서 2자리면서 20이면 2.2를 주고 30이면 2.3을 주는 식으로 구성하였습니다. \n",
        "  meta.movieId = meta.movieId.astype(int) #이것도 데이터 프레임의 형식을 바꿔주었습니다.\n",
        "  meta.vote_average = meta.vote_average.astype(float)\n",
        "  meta.vote_count = meta.vote_count.astype(int)\n",
        "  print(meta.head())\n",
        "  meta.info() # 정보를 확인하고 결측값이랑 형식을 다시 한 번 확인합니다. \n",
        "  meta.describe() #Adj를 만들기 위해 vote_count의 최댓값을 파악합니다. 자리수가 몇개인지 알기 위해 출력합니다. 5자리가 최대군요.\n",
        "  \n",
        "  for idx in range(len(meta)):\n",
        "      if str(meta.vote_average[idx])[-1] in [\"1\",\"2\",\"3\",\"4\",\"6\",\"7\",\"8\",\"9\"]:\n",
        "        meta.vote_round[idx] = round(meta.vote_average[idx],0)\n",
        "      else:\n",
        "        meta.vote_round[idx] = meta.vote_average[idx]\n",
        "  \n",
        "  \n",
        "  for idx in range(len(meta)):\n",
        "      if len(str(meta.vote_count[idx])) == 1:\n",
        "          meta.Adj[idx] = 1.1 / 250\n",
        "      if len(str(meta.vote_count[idx])) == 2:\n",
        "        if str(meta.vote_count[idx])[0] == \"1\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.1) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"2\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.2) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"3\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.3) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"4\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.4) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"5\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.5) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"6\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.6) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"7\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.7) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"8\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.8) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"9\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 2.9) / 250\n",
        "      if len(str(meta.vote_count[idx])) == 3:\n",
        "        if str(meta.vote_count[idx])[0] == \"1\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.1) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"2\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.2) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"3\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.3) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"4\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.4) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"5\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.5) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"6\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.6) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"7\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.7) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"8\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.8) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"9\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 3.9) / 250\n",
        "      if len(str(meta.vote_count[idx])) == 4:\n",
        "        if str(meta.vote_count[idx])[0] == \"1\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.1) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"2\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.2) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"3\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.3) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"4\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.4) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"5\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.5) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"6\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.6) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"7\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.7) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"8\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.8) / 250\n",
        "        if str(meta.vote_count[idx])[0] == \"9\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 4.9) / 250\n",
        "      if len(str(meta.vote_count[idx])) == 5:\n",
        "        if str(meta.vote_count[idx])[0] == \"1\":\n",
        "          meta.Adj[idx] = (meta.vote_average[idx] * 5.1) / 250\n",
        "  \n",
        "  meta['genres'] = meta['genres'].apply(parse_genres)\n",
        "\n",
        "  data = pd.merge(ratings, meta, on='movieId', how='inner')\n",
        "  data.info() # 데이터 형식과 결측값 확인하기. \n",
        "  data.userId = data.userId.astype('int32') # 데이터 형식 중에서 숫자가 32크기 이하여야 계산이 되더라구요. 그래서 32로 바꿔주기\n",
        "  data.movieId = data.movieId.astype('int32')\n",
        "  data.rating\t = data.rating.astype('float32')\n",
        "  data.vote_average = data.vote_average.astype('float32')\n",
        "  data.vote_count = data.vote_count.astype('int32')\n",
        "  data.vote_round = data.vote_round.astype(str).astype('float32')\n",
        "  data.Adj = pd.to_numeric(data.Adj, errors='coerce').astype('float32')\n",
        "  return data, meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Uo1yeKpBks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_genres(genres_str):\n",
        "    genres = json.loads(genres_str.replace('\\'', '\"'))\n",
        "    \n",
        "    genres_list = []\n",
        "    for g in genres:\n",
        "        genres_list.append(g['name'])\n",
        "\n",
        "    return genres_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H82tg5lAoKpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 구한 예측값에 Adj를 추가하기 위해서 만든 함수입니다. \n",
        "def Estimate_Score_sum4(df_user,user_df):\n",
        "  dfsort = df_user.groupby('vote_round')['vote_round'].agg(['count'])\n",
        "  dfsort = dfsort.sort_values(by='count',ascending = False)\n",
        "  dfsort[\"countAdj\"] = ''\n",
        "  dfsort['Rank'] = ''\n",
        "  for idx in range(len(dfsort)):\n",
        "    dfsort[\"countAdj\"].iloc[idx] = dfsort['count'].iloc[idx] / 100 \n",
        "    dfsort['Rank'].iloc[idx] = idx+1 \n",
        "  dfsort.reset_index(inplace=True)\n",
        "  for idx in range(len(user_df)):\n",
        "    for idx2 in range(len(dfsort)):\n",
        "      if user_df.vote_round.iloc[idx] ==  dfsort.index[idx2]:\n",
        "          user_df.Adj[idx]+= dfsort.countAdj[idx2]\n",
        "  for idx in range(len(user_df)):\n",
        "    user_df.Estimate_Score[idx] += user_df.Adj[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQr9m-elqGmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ALS(df_p):\n",
        "      R = np.array(df_p) # ALS하기 위해 배열이 필요해서 배열로 바꿔준다.\n",
        "      R = np.nan_to_num(R) #nan_to_num : nan 값을 0으로 바꾸기 위한 함수\n",
        "      r_lambda = 40 # 블로그에서 언급하길 논문에서 가장 좋은 결과를 냈다는 값을 가져다 쓴다.\n",
        "      nf = 200\n",
        "      alpha = 40\n",
        "\n",
        "      R = np.array(df_p)# ALS하기 위해 배열이 필요해서 배열로 바꿔준다.\n",
        "      R = np.nan_to_num(R) #nan_to_num : nan 값을 0으로 바꾸기 위한 함수\n",
        "\n",
        "      nu = R.shape[0] # nu는 userId의 개수\n",
        "      ni = R.shape[1] # ni는 movieId의 개수 \n",
        "\n",
        "      # initialize X and Y with very small values\n",
        "      X = np.random.rand(nu, nf) * 0.01   # np.random.rand : 0 ~ 1의 균일분포 표준정규분포 난수를 matrix array(m(행),n(컬럼)) 생성\n",
        "      Y = np.random.rand(ni, nf) * 0.01\n",
        "\n",
        "      P = np.copy(R) \n",
        "      P[P > 0] = 1  #위의 사용자 평점들을 1로 바꿔줘야 하기 때문에 0보다 크면 1로 다 바꿔준다.\n",
        "      C = 1 + alpha * R\n",
        "\n",
        "      predict_errors = []\n",
        "      confidence_errors = []\n",
        "      regularization_list = []\n",
        "      total_losses = []\n",
        "\n",
        "      for i in range(2):\n",
        "        if i != 0:\n",
        "            yT = np.transpose(Y) # np.transpose 행과 열을 바꾸는 함수\n",
        "            for u in range(nu):\n",
        "                Cu = np.diag(C[u]) # np.diag 대각행렬 만드는 함수\n",
        "                yT_Cu_y = np.matmul(np.matmul(yT, Cu), Y) # np.matmul 두 배열의 행렬곱\n",
        "                lIy = np.dot(r_lambda, np.identity(nf)) # np.dot 두 배열의 내적곱, np.identity 2차원의 정방단위행렬 객체를 반환 \n",
        "                yT_Cu_pu = np.matmul(np.matmul(yT, Cu), P[u])\n",
        "                X[u] = np.linalg.solve(yT_Cu_y + lIy, yT_Cu_pu) # np.linalg.solve 연립방정식 해 풀기.\n",
        "\n",
        "            xT = np.transpose(X)\n",
        "            for i in range(ni):\n",
        "                Ci = np.diag(C[:, i])\n",
        "                xT_Ci_x = np.matmul(np.matmul(xT, Ci), X)\n",
        "                lIx = np.dot(r_lambda, np.identity(nf))\n",
        "                xT_Ci_pi = np.matmul(np.matmul(xT, Ci), P[:, i])\n",
        "                Y[i] = np.linalg.solve(xT_Ci_x + lIx, xT_Ci_pi)\n",
        "        predict = np.matmul(X, np.transpose(Y))\n",
        "        predict_error = np.square(P - predict)\n",
        "        confidence_error = np.sum(C * predict_error)\n",
        "        regularization = r_lambda * (np.sum(np.square(X)) + np.sum(np.square(Y)))\n",
        "        total_loss = confidence_error + regularization\n",
        "        # predict_error, confidence_error, regularization, total_loss = loss_function(C, P, predict, X, Y, r_lambda)\n",
        "\n",
        "        predict_errors.append(predict_error)\n",
        "        confidence_errors.append(confidence_error)\n",
        "        regularization_list.append(regularization)\n",
        "        total_losses.append(total_loss)\n",
        "\n",
        "      predict = np.matmul(X, np.transpose(Y))\n",
        "      print('final predict')\n",
        "      print([predict])\n",
        "\n",
        "      return  predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjAjlSGM0fyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reader = Reader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpaMZlxs5hla",
        "colab_type": "text"
      },
      "source": [
        "알고리즘 별 cross_validate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np3rTvXcg92F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "svd = SVD()\n",
        "slope = SlopeOne()\n",
        "nmf = NMF()\n",
        "\n",
        "bsl_options = {'method': 'als',\n",
        "'n_epochs': 5,\n",
        "'reg_u': 12,\n",
        "'reg_i': 5\n",
        "}\n",
        "als = BaselineOnly(bsl_options=bsl_options)\n",
        "\n",
        "als_result = cross_validate(als, data, measures=['RMSE', 'MAE'],cv=5, verbose=False) #evaluate 대신 cross_validate\n",
        "slope_result = cross_validate(slope, data, measures=['RMSE', 'MAE'],cv=5, verbose=False) #evaluate 대신 cross_validate\n",
        "svd_result = cross_validate(svd, data, cv = 5,  measures=['RMSE', 'MAE']) #evaluate 대신 cross_validate사용\n",
        "nmf_result = cross_validate(nmf, data, measures=['RMSE', 'MAE'],cv=5, verbose=False) #evaluate 대신 cross_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHHrBiceC1Ba",
        "colab_type": "text"
      },
      "source": [
        "#알고리즘에 따른 RMSE, MAE 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7zlS9O25aIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(slope_result)\n",
        "print(svd_result)\n",
        "print(nmf_result)\n",
        "print(als_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX4cXWwQ1ntK",
        "colab_type": "text"
      },
      "source": [
        "# 유저에 따른 개인 영화 추천"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRme2uhJVtRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta['genres'] = meta['genres'].apply(parse_genres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDRc4Zjw02KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user_difference(data,usernumber,rating,moviedata,dropdata,reader,svd):\n",
        "    df = data\n",
        "    df_user = df[(df['userId'] == usernumber) & (df['rating'] == rating)]\n",
        "    df_user = df_user.set_index('movieId')\n",
        "    df_user = df_user.join(moviedata)['original_title']\n",
        "    print(df_user)\n",
        "\n",
        "    user_release_ratio_list = user_release_ratio(df, usernumber) # 유저의 년도 비율을 가져온다.\n",
        "\n",
        "    user_df = moviedata.copy()\n",
        "    user_df = user_df[~user_df['movieId'].isin(dropdata)]\n",
        "    data1 = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data1.build_full_trainset()\n",
        "    svd.fit(trainset)\n",
        "    user_df['Estimate_Score'] = user_df['movieId'].apply(lambda x: svd.predict(usernumber, x).est)\n",
        "    # user_df = user_df.drop('movieId', axis = 1)\n",
        "    user_df = user_df.sort_values('Estimate_Score', ascending=False)\n",
        "    print(user_df.head(10))\n",
        "\n",
        "    return user_df\n",
        "user_df665 = user_difference(df,665,5,meta,drop_movie_list,reader,svd)\n",
        "user_df664 = user_difference(df,664,5,meta,drop_movie_list,reader,svd)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc5qMPCo1hXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(user_df665)\n",
        "print(user_df664)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVyWhHEgRB7r",
        "colab_type": "text"
      },
      "source": [
        "# 유저의 변화에 따른 영화추천"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2iXR-n6IAzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user_difference(data,usernumber,rating,moviedata,dropdata,reader,svd):\n",
        "    df = data\n",
        "    df_user = df[(df['userId'] == usernumber) & (df['rating'] == rating)]\n",
        "    df_user = df_user.set_index('movieId')\n",
        "    df_user = df_user.join(moviedata)['original_title']\n",
        "    print(df_user)\n",
        "\n",
        "    user_release_ratio_list = user_release_ratio(df, usernumber) # 유저의 년도 비율을 가져온다.\n",
        "\n",
        "    user_df = moviedata.copy()\n",
        "    user_df = user_df[~user_df['movieId'].isin(dropdata)]\n",
        "    data1 = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data1.build_full_trainset()\n",
        "    svd.fit(trainset)\n",
        "    user_df['Estimate_Score'] = user_df['movieId'].apply(lambda x: svd.predict(usernumber, x).est)\n",
        "    # user_df = user_df.drop('movieId', axis = 1)\n",
        "    user_df = user_df.sort_values('Estimate_Score', ascending=False)\n",
        "    print(user_df.head(10))\n",
        "\n",
        "    return user_df\n",
        "user_1 = user_difference(df,1,5,meta,drop_movie_list,reader,svd)\n",
        "df2 = df\n",
        "df2.loc[1] = [1,5502,5.0]\n",
        "df2.loc[2] = [1,5991.0,5.0]\n",
        "add_user_1 = user_difference(df2,1,5,meta,drop_movie_list,reader,svd)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6WYWcNl2Jzh",
        "colab_type": "text"
      },
      "source": [
        "# 변수 가중치에 따른 영화 추천"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIPI9Sj72IAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def variable_weight(data,usernumber,rating,moviedata,dropdata,reader,algo):\n",
        "    df = data\n",
        "    df_user = df[(df['userId'] == usernumber) & (df['rating'] == rating)]\n",
        "    df_user = df_user.set_index('movieId')\n",
        "    df_user = df_user.join(moviedata)['original_title']\n",
        "    # print(df_user)\n",
        "\n",
        "    user_release_ratio_list = user_release_ratio(df, usernumber) # 유저의 년도 비율을 가져온다.\n",
        "    # print(user_release_ratio_list)\n",
        "    user_pop_ratio_list = user_pop_ratio(df, usernumber) # 유저의 popularity 비율을 가져온다.\n",
        "    # print(user_pop_ratio_list)\n",
        "    user_language_ratio_list = user_language_ratio(df, usernumber) # 유저의 language 비율을 가져온다.\n",
        "    # print(user_language_ratio_list)\n",
        "\n",
        "    user_df = moviedata.copy()\n",
        "    user_df = user_df[~user_df['movieId'].isin(dropdata)]\n",
        "    data1 = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data1.build_full_trainset()\n",
        "    algo.fit(trainset)\n",
        "    user_df['Estimate_Score'] = user_df['movieId'].apply(lambda x: algo.predict(usernumber, x).est)\n",
        "    # user_df = user_df.drop('movieId', axis = 1)\n",
        "    user_df = user_df.sort_values('Estimate_Score', ascending=False)\n",
        "    # print(user_df.head(10))\n",
        "\n",
        "    user_df_sum = Estimate_Score_sum1(user_df, user_release_ratio_list)\n",
        "    user_df_total = Estimate_Score_sum1(user_df, user_release_ratio_list)\n",
        "    user_df_sum_relase = user_df_sum.sort_values('Estimate_Score', ascending=False)\n",
        "    print(\"개봉일 별 가중치\")\n",
        "    print(user_df_sum_relase.head(10))\n",
        "\n",
        "    user_df_sum = Estimate_Score_sum2(user_df, user_pop_ratio_list)\n",
        "    user_df_total = Estimate_Score_sum2(user_df_total, user_pop_ratio_list)\n",
        "    user_df_sum_pop = user_df_sum.sort_values('Estimate_Score', ascending=False)\n",
        "    print(\"인기 별 가중치\")\n",
        "    print(user_df_sum_pop.head(10))\n",
        "\n",
        "    user_df_sum = Estimate_Score_sum3(user_df, user_language_ratio_list)\n",
        "    user_df_total = Estimate_Score_sum3(user_df_total, user_language_ratio_list)\n",
        "\n",
        "    user_df_sum_lang = user_df_sum.sort_values('Estimate_Score', ascending=False)\n",
        "    print(\"언어 별 가중치\")\n",
        "    print(user_df_sum_lang.head(10))\n",
        "\n",
        "    user_df_total = user_df_total.sort_values('Estimate_Score', ascending=False)\n",
        "    print(user_df_total.head(10))\n",
        "\n",
        "    return user_df_sum_relase, user_df_sum_pop, user_df_sum_lang, user_df_total\n",
        "user_df_sum_relase,user_df_sum_pop, user_df_sum_lang, user_df_total = variable_weight(df,665,5,meta,drop_movie_list,reader,svd)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8giINH94sBmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vote_data, vote_meta = user_vote_ratio()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmhFzuApr27R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#이게 맨 처음에 SVD에 가중치 준 함수입니다. 여기서도 svd, reader, dero_movie_list는 그냥 함수안에 바로 넣었습니다.\n",
        "def variable_weight2(data,usernumber,rating,moviedata):\n",
        "    df = data.copy()\n",
        "    df_user = df[(df['userId'] == usernumber) & (df['rating'] == rating)]\n",
        "    df_user = df_user.set_index('movieId')\n",
        "    # print(df_user.iloc[:,2]) #제가 만든 meta에 이미 title이 있어서join을 할 필요가 없었습니다.\n",
        "    \n",
        "    \n",
        "    user_df = moviedata.copy()\n",
        "    user_df = user_df[~user_df['movieId'].isin(drop_movie_list)]\n",
        "    data1 = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data1.build_full_trainset()\n",
        "    svd.fit(trainset)\n",
        "    user_df['Estimate_Score'] = user_df['movieId'].apply(lambda x: svd.predict(usernumber, x).est)\n",
        "    user_df.reset_index(inplace=True, drop=True)\n",
        "   \n",
        "    \n",
        "    Estimate_Score_sum4(df_user,user_df) \n",
        "    # user_df = user_df.drop('movieId', axis = 1)\n",
        "    user_df = user_df.sort_values(('Estimate_Score'), ascending=False)\n",
        "    user_df_sum_vote = pd.DataFrame(user_df)\n",
        "    user_df_sum_vote = user_df_sum_vote.iloc[:,[0,1,3,4,5,8]]\n",
        "\n",
        "\n",
        "    return user_df_sum_vote\n",
        "user_df_sum_vote = variable_weight2(vote_data,665,5,vote_meta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEVaEczr9ZDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(user_df_sum_relase.head(10))\n",
        "print(user_df_sum_pop.head(10)) \n",
        "print(user_df_sum_lang.head(10))\n",
        "print(user_df_sum_vote.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT3HwqpQ10Et",
        "colab_type": "text"
      },
      "source": [
        "# 알고리즘에 따른 영화 추천"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEWM9T5ySTF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def userRec3(data,usernumber,rating,moviedata,dropdata,reader,algo):\n",
        "    df = data\n",
        "    df_user = df[(df['userId'] == usernumber) & (df['rating'] == rating)]\n",
        "    df_user = df_user.set_index('movieId')\n",
        "    df_user = df_user.join(moviedata)['original_title']\n",
        "    # print(df_user)\n",
        "\n",
        "    user_release_ratio_list = user_release_ratio(df, usernumber) # 유저의 년도 비율을 가져온다.\n",
        "    # print(user_release_ratio_list)\n",
        "    user_pop_ratio_list = user_pop_ratio(df, usernumber) # 유저의 popularity 비율을 가져온다.\n",
        "    # print(user_pop_ratio_list)\n",
        "    user_language_ratio_list = user_language_ratio(df, usernumber) # 유저의 language 비율을 가져온다.\n",
        "    # print(user_language_ratio_list)\n",
        "\n",
        "    user_df = moviedata.copy()\n",
        "    user_df = user_df[~user_df['movieId'].isin(dropdata)]\n",
        "    data1 = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data1.build_full_trainset()\n",
        "    algo.fit(trainset)\n",
        "    user_df['Estimate_Score'] = user_df['movieId'].apply(lambda x: algo.predict(usernumber, x).est)\n",
        "    # user_df = user_df.drop('movieId', axis = 1)\n",
        "    user_df = user_df.sort_values('Estimate_Score', ascending=False)\n",
        "    # print(user_df.head(10))\n",
        "\n",
        "    # user_df_sum = Estimate_Score_sum1(user_df, user_release_ratio_list)\n",
        "    # # user_df_sum = user_df_sum.sort_values('Estimate_Score', ascending=False)\n",
        "    # # print(user_df_sum.head(10))\n",
        "\n",
        "    # user_df_sum = Estimate_Score_sum2(user_df_sum, user_pop_ratio_list)\n",
        "    # # user_df_sum = user_df_sum.sort_values('Estimate_Score', ascending=False)\n",
        "    # # print(user_df_sum.head(10))\n",
        "\n",
        "    # user_df_sum = Estimate_Score_sum3(user_df_sum, user_language_ratio_list)\n",
        "    # user_df_sum = user_df_sum.sort_values('Estimate_Score', ascending=False)\n",
        "    # print(user_df_sum.head(10))\n",
        "\n",
        "    return user_df\n",
        "als_recomend = userRec3(df,665,5,meta,drop_movie_list,reader,als)\n",
        "svd_recomend = userRec3(df,665,5,meta,drop_movie_list,reader,svd)\n",
        "slope_recomend = userRec3(df,665,5,meta,drop_movie_list,reader,slope)\n",
        "nmf_recomend = userRec3(df,665,5,meta,drop_movie_list,reader,nmf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxxvHVs7EpZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(als_recomend)\n",
        "print(svd_recomend)\n",
        "print(slope_recomend)\n",
        "print(nmf_recomend)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BDPrXGatc6Q",
        "colab_type": "text"
      },
      "source": [
        "## TMDB OPEN API로 추천 영화 포스터 가져오기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMb36Sjjw_wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미지를 얻어오기 위하며\n",
        "# 함수 내에 있는 user_df = user_df.drop('movieId', axis = 1)를 모두 주석처리하고 다시 진행함.\n",
        "# movieId가 필요하기 때문에 주석처리하고 진행."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvBeTBMBtoWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "89d2199c-915d-4714-b90a-521f82a3c191"
      },
      "source": [
        "!pip install tmdbv3api   # tmdb api가져오기 위한 인스톨"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tmdbv3api in /usr/local/lib/python3.6/dist-packages (1.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tmdbv3api) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbv3api) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbv3api) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbv3api) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbv3api) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNVrHuf8vsGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML \n",
        "from IPython.display import display \n",
        "import requests\n",
        "import cv2\n",
        "import urllib.request\n",
        "import urllib\n",
        "import tweepy\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r4fkA6JvwAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_recommendations(data):\n",
        "    api_key = '?api_key=8a98ba13f2855e4a5c4aae1af3e81974'\n",
        "    url = 'https://api.themoviedb.org/3/movie/'\n",
        "    urls = []\n",
        "    start = 0\n",
        "    data['imgUrl'] = ''\n",
        "    for i in range(len(data)):\n",
        "                mov_num = str(data['movieId'].iloc[i])\n",
        "                JSONcontent = requests.get(url + mov_num + api_key)\n",
        "                response = JSONcontent.json()\n",
        "                base_url = 'https://image.tmdb.org/t/p/original'\n",
        "                img_url = response['poster_path']\n",
        "                if  img_url != None : \n",
        "                  image_url = base_url + img_url\n",
        "                  urls.append(image_url)\n",
        "                  data['imgUrl'].iloc[i] = urls[i]\n",
        "                  print(data['imgUrl'].iloc[i])\n",
        "                else:\n",
        "                  image_url = \"None\"\n",
        "                  urls.append(image_url)\n",
        "                  data['imgUrl'].iloc[i] = 'None'\n",
        "                  print(data['imgUrl'].iloc[i])\n",
        "                \n",
        "\n",
        "    images = ''\n",
        "    for link in urls:\n",
        "      if link != '':\n",
        "        images += \"<img style= 'width: 150px; margin: 1px; float: left; border: 1px solid black;' src= '%s'>\" % link\n",
        "    display(HTML(images))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neQvAm9Bulu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_df665 = user_df665.head(12) #위에서 뽑은 데이터 정리.\n",
        "user_df665_poster = display_recommendations(user_df665)\n",
        "user_df665_poster2 = user_df665_poster.to_csv('../content/drive/My Drive/user_df665_poster.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqQXMeBNvA7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_df664 = user_df664.head(12)\n",
        "user_df664_poster = display_recommendations(user_df664)\n",
        "user_df664_url_data = user_df664_poster.to_csv('../content/drive/My Drive/user_df664_poster.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npRmLKgBQzbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_1_url = user_1.head(12)\n",
        "user_1_ur12 = display_recommendations(user_1_url)\n",
        "user_1_ur12.to_csv('../content/drive/My Drive/user_1_url.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fujv9s8xQ6qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add_user_1_10 = add_user_1.head(12)\n",
        "add_user_1_10_url = display_recommendations(add_user_1_10)\n",
        "add_user_1_10_url.to_csv('../content/drive/My Drive/add_user_1_10_url.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHdCj_7lvgRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_df_sum_relase1 = user_df_sum_relase.head(12)\n",
        "user_df_sum_pop1 = user_df_sum_pop.head(12)\n",
        "user_df_sum_lang1 = user_df_sum_lang.head(12)\n",
        "user_df_sum_vote1 = user_df_sum_vote.head(12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuQWJfZxvizB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_df_sum_relase3 = display_recommendations(user_df_sum_relase1)\n",
        "user_df_sum_pop3 = display_recommendations(user_df_sum_pop1)\n",
        "user_df_sum_lang3 = display_recommendations(user_df_sum_lang1)\n",
        "user_df_sum_vote3 = display_recommendations(user_df_sum_vote1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5ETuQ1zwNN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_df_sum_relase4 = user_df_sum_relase3.to_csv('../content/drive/My Drive/user_df_sum_relase_Url.csv')\n",
        "user_df_sum_pop4 = user_df_sum_pop3.to_csv('../content/drive/My Drive/user_df_sum_pop_Url.csv')\n",
        "user_df_sum_lang4 = user_df_sum_lang3.to_csv('../content/drive/My Drive/user_df_sum_lang_Url.csv') \n",
        "user_df_sum_vote4 = user_df_sum_vote3.to_csv('../content/drive/My Drive/user_df_sum_vote_Url.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gEhtZZUvoAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "als_recomend1 = als_recomend.head(12)\n",
        "svd_recomend1 = svd_recomend.head(12)\n",
        "slope_recomend1 = slope_recomend.head(12)\n",
        "nmf_recomend1 = nmf_recomend.head(12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GECjPOb5vyzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "als_recomend_poster = display_recommendations(als_recomend1)\n",
        "svd_recomend_poster = display_recommendations(svd_recomend1)\n",
        "slope_recomend_poster = display_recommendations(slope_recomend1)\n",
        "nmf_recomend_poster = display_recommendations(nmf_recomend1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWf1ErLwCnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "als_recomend_poster1 = als_recomend_poster.to_csv('../content/drive/My Drive/als_recomend_poster.csv')\n",
        "svd_recomend_poster1 = svd_recomend_poster.to_csv('../content/drive/My Drive/svd_recomend_poster.csv')\n",
        "slope_recomend_poster1 = slope_recomend_poster.to_csv('../content/drive/My Drive/slope_recomend_poster.csv')\n",
        "nmf_recomend_poster1 = nmf_recomend_poster.to_csv('../content/drive/My Drive/nmf_recomend_poster.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}